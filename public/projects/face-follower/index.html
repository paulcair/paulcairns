<!DOCTYPE html>
<html lang="en" dir="ltr">
<head><script src="/paulcairns/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=paulcairns/livereload" data-no-instant defer></script>
  <title>Paul Cairns - Face Follower - An AI and hardware fusion</title>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="description" content="Creative Portfolio Template">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0">
<meta name="author" content="Themefisher">
<meta name="generator" content="Themefisher Kross Template v1.0">

  <link rel="stylesheet" href="/paulcairns/assets/bootstrap/css/bootstrap.min.css">
<link rel="stylesheet" href="/paulcairns/assets/css/main.css?v=1731190667">





  <link rel="stylesheet" href="/paulcairns/assets/plugins/slick/slick.css">
  
  <link rel="stylesheet" href="/paulcairns/assets/plugins/themify-icons/themify-icons.css">
  <link rel="stylesheet" href="/paulcairns/assets/plugins/css/css.css">

  
  <link href="/paulcairns/assets/css/style.css" rel="stylesheet">
  <script src="/paulcairns/assets/plugins/jQuery/jquery.min.js"></script>
  <script src="/paulcairns/assets/plugins/bootstrap/bootstrap.min.js"></script>
  <script src="/paulcairns/assets/plugins/shuffle/shuffle.min.js"></script> 
  <script src="/paulcairns/assets/js/typewrite.js"></script> 
  

</head>
<body>

  
<header class="navigation">
    <nav class="navbar navbar-dark">
      <a class="navbar-brand" href="http://localhost:1313/paulcairns//index.html"><img src="http://localhost:1313/paulcairns//paul-logo.png" alt="FabAcadeLogo"></a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navigation"
        aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
  
      <div class="collapse navbar-collapse text-center" id="navigation">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="http://localhost:1313/paulcairns//index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="http://localhost:1313/paulcairns//about/paul-cairns">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="http://localhost:1313/paulcairns//#projects">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="http://localhost:1313/paulcairns//skillsportfolio">Skills Portfolio</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="http://localhost:1313/paulcairns//publications">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="http://localhost:1313/paulcairns//videos">Videos</a>
          </li>
        </ul>
      </div>
    </nav>
  </header>

  <section class="hero-area bg-dark" id="parallax">
    <div class="container">
      <div class="row">
        <div class="col-lg-11 bg-green p-3 rounded-lg mx-auto">
          
          <p class="text-white text-center text-decoration-none font-tertiary" style="font-size: 80px; line-height:1;">
            <a href="" class="typewrite" data-period="2000" data-type='["The Face Follower", "A 3D printed hardware using Arduino controller and python based face-detection AI.", "Please browse at your convenience."," Enjoy!" ]'>
              <span class="wrap"></span>
            </a>
          </p>
          
          
          <h5 class="text-white bg-green text-decoration-none text-center py-2">
            The Face Follower is a little project that combines AI face-detection python programming, with 3D printed hardware and Arduino based micro-controller with servo motion control. 
          </h5>
          
        </div>
      </div>
    </div>
  </section>

  <div class="container">
    <h1 class="text-center text-decoration-none pt-5">Face Follower - An AI and hardware fusion</h1>
  </div>


<main class="py-5">
  <div class="row justify-content-center px-4">
    <img class="img-fluid position: center mb-4" src="/paulcairns/projects/face-follower/" alt="">
  </div>  
  <div class = "container mt-5">
    <div class = "card py-4">
    <video controls autoplay loop muted class ="embed-responsive-item"> 
     <source
        src="demo.mp4" 
        type="video/mp4">
    </video>
</div>
<h1 id="background-and-inspiration">Background and Inspiration</h1>
<p>I came across this video on social media and got inspired to see if I could replicate it by dusting off an old face detection app I made that uses OpenCV.</p>
<p>The video of the project that inspired this is below:</p>
<div style="position: relative; padding-bottom: 56.25%; overflow: hidden;">
    <iframe style="position: absolute; width: 100%; height: 100%;"
        src="https://www.youtube.com/embed/f2TUxoaKIsA" 
        allowfullscreen 
        frameborder="0"
        class = "pt-3 pb-5">
    </iframe>
</div>
<p>As part of the challenge, I wanted to avoid looking at any documentation that the project included and just try to design the project from scratch using only the video as guidance and to see how I might be able to improve upon the hardware.</p>
<p>Once I completed the project, I finally opened the github repository for his project to see our difference in approach. In the end the overall approach was very similar, one major difference, which I think made his solution more elegant, was that he uses the python program to control the Arduino directly, whereas I have programmed the Arduino seperately and am sending the coordinates to the arduino from my laptop over the USB Serial, which results in a minor delay in the reactivity of the servo, compared to his project.</p>
<p>Either way, it was a really fun project and experience. I will share the methodology and details of my approach to the problem below.</p>
<h2 id="python-ai-face-detection-app">Python AI face detection App</h2>
<p>Here is a video of the python program in action:</p>
<div class = "card py-4">
    <video controls autoplay loop muted class ="embed-responsive-item"> 
     <source
        src="coord.mp4" 
        type="video/mp4">
    </video>
</div>
<p>Below is the python code:</p>
<pre tabindex="0"><code>import cv2
import os
import time
import serial
from kivy.app import App
from kivy.uix.gridlayout import GridLayout
from kivy.uix.label import Label
from kivy.uix.button import Button

#Get the path of the current script
script_path=os.path.abspath(__file__)

# Get the directory containing the script
script_directory = os.path.dirname(script_path)

# Concatenate the script directory with the face XML file name
cascade_face_path = os.path.join(script_directory, &#39;haarcascade_frontalface_default.xml&#39;)

# Concatenate the script directory with the Smile XML file name
cascade_smile_path = os.path.join(script_directory, &#39;haarcascade_smile.xml&#39;)

# Open a connection to the serial port (adjust the port and baud rate as needed)
# ser = serial.Serial(&#39;/dev/ttyACM0&#39;, 115200)

# Create an App class called FaceDetect
class FaceDetect(App):

    #Build a window named self and set the columns
    def build(self):
        self.window = GridLayout()
        self.window.cols = 1
        self.window.size_hint = (0.6, 0.7)
        self.window.pos_hint = {&#34;center_x&#34;:0.5, &#34;center_y&#34;:0.5 }
    
        # Add widgets to the window

        # Create a lable widget with a greeting
        self.greeting = Label(
                        text = &#34;Welcome to Paul&#39;s Facial Recognition App&#34;,
                        font_size = 32,
                        color = &#39;#00FFCE&#39;
                        )
        self.window.add_widget(self.greeting)

        # Create a label widget with a prompt
        self.prompt = Label(
                      text = &#34;Please select the functionality&#34;,
                      font_size = 16
                      )
        self.window.add_widget(self.prompt)

        # Create a button widget with face detector only
        self.face = Button(
                      text = &#34;Track face only&#34;,
                      size_hint = (1,0.5),
                      bold = True,
                      background_color = &#39;#00FFCE&#39;
                      )
        self.face.bind(on_press = self.track_face)
        self.window.add_widget(self.face)

        # Create a button widget with face and smile detector
        self.face_smile = Button(
                      text = &#34;Track face and smile&#34;,
                      size_hint = (1,0.5),
                      bold = True,
                      background_color = &#39;#00FFCE&#39;
                      )
        self.face_smile.bind(on_press = self.track_face_smile)
        self.window.add_widget(self.face_smile)
     
        return self.window
        
    #Function that launches face tracker on button press
    def track_face(self, instance):

        # Load some pre-trained data on face frontals from opencv (haar cascade algorithm)
        trained_face_data = cv2.CascadeClassifier(cascade_face_path)

        # Choose an image to detect faces in
        #img = cv2.imread(&#39;paulface.jpg&#39;)

        # Capture video from webcam
        webcam = cv2.VideoCapture(0)

        while True:
            #Read the current frame
            succesful_frame_read, frame = webcam.read()

            # Convert the image to greyscale
            img_greyscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Detect faces
            face_coordinates = trained_face_data.detectMultiScale(img_greyscale)

            # Initialize empty variables to find the bigest face 
            biggest_face_width = 0
            biggest_face = None
            # last_biggest_face = (320,240,0,0)

            # Find the biggest face in the face_coordinates array
            for (x,y,w,h) in face_coordinates:
                if w &gt; biggest_face_width:
                    biggest_face_width = w
                    biggest_face = (x,y,w,h)
            
                cv2.rectangle(frame,(x, y),(x+w, y+h),(0,255,0), 3)

            # If a face is detected, send face coordinates to Arduino via serial port
            if biggest_face is not None:
                # last_biggest_face = biggest_face
                x, y, w, h = biggest_face

                cv2.rectangle(frame,(x, y),(x+w, y+h),(0,0, 255), 3)

                coordinates_string = f&#34;{x},{y},{w},{h}\n&#34;
                # ser.write(coordinates_string.encode(&#39;utf-8&#39;))
                print(coordinates_string)
            # else:
            #     x, y, w, h = last_biggest_face
            #     none_detected = f&#34;{x},{y},{w},{h}\n&#34;
            #     ser.write(none_detected.encode(&#39;utf-8&#39;))
            #     print(none_detected)

            #Flip the frame horizontally
            mirrored_frame = cv2.flip(frame, 1)      

            #Add Label with prompt to press ESC to exit
            cv2.putText(mirrored_frame, &#39;PRESS ESC TO EXIT PROGRAM&#39;, (40 ,40), fontScale = 2, fontFace = cv2.FONT_HERSHEY_PLAIN, color=(255, 255, 255))

            # Display the image with boxes around the detected faces
            
            cv2.imshow(&#39;Clever Programmer Face Detector Grey&#39;, mirrored_frame)
            key = cv2.waitKey(1)

            #Exit the program if Q key is pressed
            if key == 27:
                break
            
        
        #Realease the webcam
        webcam.release()
        cv2.destroyAllWindows()
 
    # Function that launches face and smile tracker on button press
    def track_face_smile(self, instance):

        # Load some pre-trained data on face frontals and smiles from opencv (haar cascade algorithm)
        trained_face_data = cv2.CascadeClassifier(cascade_face_path)
        trained_smile_data = cv2.CascadeClassifier(cascade_smile_path)

        # Capture video from webcam
        webcam = cv2.VideoCapture(0)

        while True:
            #Read the current frame
            succesful_frame_read, frame = webcam.read()

            # Convert the image to greyscale
            img_greyscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Detect faces
            face_coordinates = trained_face_data.detectMultiScale(img_greyscale, minNeighbors = 10)

            # Create rectangles around the detected faces and create a different color box around each one
            for (x,y,w,h) in face_coordinates:

                #Draw a rectangle around the face
                cv2.rectangle(frame,(x, y),(x+w, y+h),(0,255,0), 3)

                # Send face coordinates to Arduino via serial port
                coordinates_string = f&#34;{x},{y},{w},{h}\n&#34;
                ser.write(coordinates_string.encode(&#39;utf-8&#39;))

                # Create image the size of each face box
                the_face = frame[y:y+h, x:x+w]

                #Change facebox subset to greuscale
                face_greyscale = cv2.cvtColor(the_face, cv2.COLOR_BGR2GRAY)

                # Search for smiles within each face box
                smiles = trained_smile_data.detectMultiScale(face_greyscale, scaleFactor = 1.3, minNeighbors = 12)
                
                # Run smile detection within each of the faces
                for (a,b,c,d) in smiles:
                    
                    #Draw a rectangle around each detected smile within the face
                    cv2.rectangle(the_face, (a, b), (a+c, b+d),(0,0,255),3)

                #Label this face as smiling
                if len(smiles) &gt; 0:
                    cv2.putText(frame, &#39;SMILING&#39;, (x ,y+h+40), fontScale = 2, fontFace = cv2.FONT_HERSHEY_PLAIN, color=(255, 255, 255))

            #Add Label with prompt to press ESC to exit
            cv2.putText(frame, &#39;PRESS ESC TO EXIT PROGRAM&#39;, (40 ,40), fontScale = 2, fontFace = cv2.FONT_HERSHEY_PLAIN, color=(255, 255, 255))

            # Display the image with boxes around the detected faces
            cv2.imshow(&#39;Clever Programmer Face and Smile Detector&#39;, frame)
            key = cv2.waitKey(1)

            
            #Exit the program if Q key is pressed
            if key == 27:
                break
            

        #Release the webcam
        webcam.release()
        cv2.destroyAllWindows()
         
# Run the App called FaceDetect   
if __name__ == &#34;__main__&#34;:
    FaceDetect().run()
</code></pre><h2 id="hardware-design">Hardware Design</h2>
<p>I designed the hardware for the face-follower using Solidworks. I cover details of the design on a seperate solidworks page. You can find it <a href="../../skillsportfolio/computer-aided-design/solidworks/">here</a></p>
<h3 id="cad">CAD</h3>
<p>I have included some of the Solidworks images and videos below:</p>
<div class="row justify-content-center">
<img class="img-fluid py-4"
     src="face-follower-assembly.PNG"
     alt="face-follower-assembly.PNG">
</div>
<div class = "card py-4">
    <video controls autoplay loop muted class ="embed-responsive-item"> 
     <source
        src="face-follower-assembly.mp4" 
        type="video/mp4">
    </video>
</div>
<h3 id="3d-printing">3D printing</h3>
<p>I 3D printed the parts using a Prusa 3D printer with PLA. I chose draft print settings. Unfortunately I didn&rsquo;t take any photos of the printing process. But I do have a photo of the end result.</p>
<div class = "row row-cols-1 row-cols-md-2 pt-4 pb-4">

    <div class = "col">
       <div class = "card">
           <img class="card-img-top"
           src="000.jpg" 
           alt="000.jpg">
        </div>
    </div>

    <div class = "col">
        <div class = "card">
            <img class="card-img-top"
            src="001.jpg" 
            alt="001.jpg">
         </div>
     </div>

</div>
<div class = "row row-cols-1 row-cols-md-2 pt-4 pb-4">

    <div class = "col">
       <div class = "card">
           <img class="card-img-top"
           src="002.jpg" 
           alt="002.jpg">
        </div>
    </div>

    <div class = "col">
        <div class = "card">
            <img class="card-img-top"
            src="003.jpg" 
            alt="003.jpg">
         </div>
     </div>

</div>
<h2 id="ardiuino-program">Ardiuino Program</h2>
<p>Below is the Arduino program. Note that I took a few different approaches, and have some of the other approaches commented out in the code.</p>
<pre tabindex="0"><code>#include &lt;Servo.h&gt;

// y Servo can go from 0 to 60 degrees
// X Servo can go from 0 to 180 degrees with forward being at 90 degrees althought it might be better to go from 90 +- 45 (45 to 135) 

int xPrevious;
int yPrevious;
int wPrevious;
int hPrevious;
int counter = 0;
int counts = 7;


const float smoothingFactor = 0.1;
float smoothedAngleX = 90.0;       
float smoothedAngleY = 0.0;  

Servo xServo;
Servo yServo;

void setup() {
  
  Serial.begin(115200);
  xServo.attach(8);
  yServo.attach(9);
  xServo.write(90);
  yServo.write(0);
}

void loop() {

  //// Code to test the servos and their positions. Uncomment this code and comment all of the code below &#34;Servo Testing&#34; to run the servo test program
  // for(int i=3; i&lt;=9; i++){
  //   int j = i*15; // for x go at increments of 15 degrees from 45 to 135 degrees
  //   int k = (i-3)*10; // for y go at increments of 10 degrees 
  //   Serial.println(j);
  //   xServo.write(j);
  //   yServo.write(k);
  //   delay(1000);
  // }
  // Serial.println(&#34;Servo Testing&#34;)
  
  // If the Serial is available, read it
  if(Serial.available()&gt;0){
    String coordinates = Serial.readStringUntil(&#39;\n&#39;);

    // Parse the coordinates printed on the serial into integers
    int x,y,w,h;
    sscanf(coordinates.c_str(), &#34;%d,%d,%d,%d&#34;, &amp;x,&amp;y,&amp;w,&amp;h);
    
    // If we are returned a strange value, set x, y, w, or h to what they were previously
    if(x&gt;640){
      x = xPrevious;
    }else{
      xPrevious = x;
    }   

    if(y&gt;640){
      y = yPrevious;
    }else{
      yPrevious = y;
    } 

    if(w&gt;640){
      w = wPrevious;
    }else{
      wPrevious = w;
    }  

    if(h&gt;640){
      h = hPrevious;
    }else{
      hPrevious = h;
    }  

    // Find the center of the box
    float xCenter = (x+(w/2)); // Account for the fact that xPosition zero is at center of screen
    float yCenter = y+(h/2);

  
    // Method 1: Take the image and convert it to cm and calculate an angle based on the geometry

    // Convert the center value of the box into a distance in cm knowing that the window frame height is 480 px and at a distance of 1m from the camera this corelates to 75cm in y and 100 cm wide
    // float xPosition = (xCenter/640)*100;
    // float yPosition = (yCenter/480)*75;

    // // Convert the x and y positions into radians
    // float xAngleRadians = atan2(xPosition, 100);
    // float yAngleRadians = atan2(yPosition, 100);

    // // Convert the x and y radians to degrees subtract from 135 and 60 degrees which are motor positions to aim at (0,0)
    // int xDegrees = 135-degrees(xAngleRadians);
    // int yDegrees = 60-degrees(yAngleRadians);//Add 90 degrees because of the way the servo arm is set up (need to correct this)
 
    // xServo.write(xDegrees);
    // yServo.write(yDegrees);
    

    // Method 2 (simpler method): Convert the x and y position coordinates into a % of the range in degrees (135 to 45 for x) and (60 to 0) for y 
    
    int xDegrees = 135-(xCenter/640)*90;
    int yDegrees = 60-(yCenter/480)*60;

    // Round to the nearest 10 degrees
    int xDegreesRounded = round(xDegrees/5.0)*5;
    int yDegreesRounded = round(yDegrees/5.0)*5;

    // Smooth out the motion
    // smoothedAngleX = smoothingFactor * xDegrees + (1 - smoothingFactor) * smoothedAngleX;
    // smoothedAngleY = smoothingFactor * yDegrees + (1 - smoothingFactor) * smoothedAngleY;
    if(counter == counts){
    xServo.write(xDegreesRounded);
    yServo.write(yDegreesRounded);

    }

    counter++;
    if(counter == counts+1){
      counter = 0;
    }
  } 
      
}
</code></pre><h2 id="links">Links</h2>
<ul>
<li><a href="https://github.com/paulcair/face-detector">github repository for python and arduino code</a></li>
<li><a href="cad.zip">CAD Files Zip folder</a></li>
<li><a href="gcode.zip">Gcode Files Zip folder</a></li>
</ul>
  
  </div> 
   
    
  </div>
</main>

<footer class="py-3 bg-primary text-white">
  <div class="container bg-primary py-3">
    &copy; <a href="https://rijnieks.com" class="text-white">Author: Paul Cairns, Layout based on Aalto Fab Lab website as designed by Kris Rijnieks</a> (Paul Cairns) 2024
  </div>
</footer>

<script type="text/javascript" src="/paulcairns/assets/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="/paulcairns/assets/plugins/bootstrap/bootstrap.min.js"></script>
<script src="/paulcairns/assets/plugins/jQuery/jquery.min.js"></script>
<script src="/paulcairns/assets/js/typewrite.js"></script>


<script src="/paulcairns/assets/plugins/jQuery/jquery.min.js"></script>

<script src="/paulcairns/assets/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/paulcairns/assets/plugins/slick/slick.min.js"></script>

<script src="/paulcairns/assets/plugins/shuffle/shuffle.min.js"></script>


<script src="/paulcairns/assets/js/script.js"></script>
<script src="/paulcairns/assets/js/typewrite.js"></script>

</body>
</html>
